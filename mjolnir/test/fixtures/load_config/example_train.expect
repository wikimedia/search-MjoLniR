global_config:
  commands:
    collect_features:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      cmd_args:
        feature-definitions: featureset:enwiki_v1
        input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
        kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
        kafka-request-topic: mjolnir_request
        kafka-result-topic: mjolnir_result
        output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      mjolnir_utility: collect_features
      mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
        dir_not_exist: !!set
          /mnt/hdfs/user/pytest/mjolnir/marker/features: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        executor-cores: '1'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/spark-submit
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.executor.memoryOverhead: '512'
        spark.task.cpus: '1'
    data_pipeline:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      cmd_args:
        input: hdfs://analytics-hadoop/wmf/data/discovery/query_clicks/daily/year=*/month=*/day=*
        kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
        kafka-request-topic: mjolnir_request
        kafka-result-topic: mjolnir_result
        min-sessions: '10'
        output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
        samples-per-wiki: '35000000'
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      mjolnir_utility: data_pipeline
      mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
        dir_not_exist: !!set
          /mnt/hdfs/user/pytest/mjolnir/marker/labeled: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        executor-cores: '1'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        jars: hdfs://analytics-hadoop/wmf/refinery/current/artifacts/refinery-hive.jar
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/spark-submit
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.executor.memoryOverhead: '512'
        spark.task.cpus: '1'
    feature_selection:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      cmd_args:
        input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
        num-features: '50'
        output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      mjolnir_utility: feature_selection
      mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
        dir_not_exist: !!set
          /mnt/hdfs/user/pytest/mjolnir/marker/pruned: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        executor-cores: '1'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/spark-submit
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.dynamicAllocation.maxExecutors: '400'
        spark.executor.memoryOverhead: '512'
        spark.locality.wait: '0'
        spark.task.cpus: '1'
    make_folds:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      cmd_args:
        input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
        max-executors: '50'
        num-folds: '5'
        num-workers: '1'
        output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      mjolnir_utility: make_folds
      mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        executor-cores: '1'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/spark-submit
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.dynamicAllocation.maxExecutors: '100'
        spark.executor.memoryOverhead: '512'
        spark.locality.wait: '0'
        spark.task.cpus: '1'
    pyspark:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        executor-cores: '1'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/pyspark
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.executor.memoryOverhead: '512'
        spark.task.cpus: '1'
    pyspark_train:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        executor-cores: '4'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/pyspark
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.executor.memoryOverhead: '6144'
        spark.task.cpus: '4'
    training_pipeline:
      autodetect:
        agg_cpu_limit: '450'
        agg_memory_limit: 1T
        baseline_memory_overhead: 512M
        bytes_per_value:
          make_folds: '29'
          train: '20'
        executor_max_memory: 50G
      cmd_args:
        input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
        output: /home/pytest/training_size/marker-global
      environment:
        HOME: /home/pytest
        PYSPARK_PYTHON: venv/bin/python
        SPARK_CONF_DIR: /etc/spark2/conf
        SPARK_HOME: /usr/lib/spark2
        USER: pytest
      mjolnir_utility: training_pipeline
      mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
      paths:
        dir_exist: !!set
          /etc/spark2/conf: null
          /home/pytest/training_size: null
        file_exist: !!set
          /srv/mjolnir/mjolnir_venv.zip: null
          /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
          /usr/lib/spark2/bin/spark-submit: null
          venv/bin/python: null
      spark_args:
        archives: /srv/mjolnir/mjolnir_venv.zip#venv
        driver-memory: 3G
        executor-cores: '1'
        executor-memory: 2G
        files: /usr/lib/libhdfs.so.0.0.0
        master: yarn
        packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
        repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
      spark_command: /usr/lib/spark2/bin/spark-submit
      spark_conf:
        spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
          -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
        spark.dynamicAllocation.executorIdleTimeout: 180s
        spark.executor.memoryOverhead: '512'
        spark.task.cpus: '1'
  wikis: []
profiles:
  large:
    commands:
      collect_features:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          feature-definitions: featureset:enwiki_v1
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
          kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
          kafka-request-topic: mjolnir_request
          kafka-result-topic: mjolnir_result
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: collect_features
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/features: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      data_pipeline:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/wmf/data/discovery/query_clicks/daily/year=*/month=*/day=*
          kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
          kafka-request-topic: mjolnir_request
          kafka-result-topic: mjolnir_result
          min-sessions: '10'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
          samples-per-wiki: '35000000'
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: data_pipeline
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/labeled: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          jars: hdfs://analytics-hadoop/wmf/refinery/current/artifacts/refinery-hive.jar
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      feature_selection:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
          num-features: '50'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: feature_selection
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/pruned: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.maxExecutors: '400'
          spark.executor.memoryOverhead: '512'
          spark.locality.wait: '0'
          spark.task.cpus: '1'
      make_folds:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
          max-executors: '50'
          num-folds: '3'
          num-workers: '1'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: make_folds
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.maxExecutors: '100'
          spark.executor.memoryOverhead: '5120'
          spark.locality.wait: '0'
          spark.task.cpus: '1'
      pyspark:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/pyspark
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      pyspark_train:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '4'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/pyspark
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '6144'
          spark.task.cpus: '4'
      training_pipeline:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          cv-jobs: '80'
          final-trees: '100'
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
          output: /home/pytest/training_size/marker-large
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: training_pipeline
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
            /home/pytest/training_size: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          driver-memory: 3G
          executor-cores: '6'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.executorIdleTimeout: 180s
          spark.dynamicAllocation.maxExecutors: '85'
          spark.executor.memoryOverhead: '6144'
          spark.task.cpus: '6'
    wikis:
    - enwiki
    - dewiki
  medium:
    commands:
      collect_features:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          feature-definitions: featureset:enwiki_v1
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
          kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
          kafka-request-topic: mjolnir_request
          kafka-result-topic: mjolnir_result
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: collect_features
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/features: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      data_pipeline:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/wmf/data/discovery/query_clicks/daily/year=*/month=*/day=*
          kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
          kafka-request-topic: mjolnir_request
          kafka-result-topic: mjolnir_result
          min-sessions: '10'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
          samples-per-wiki: '35000000'
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: data_pipeline
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/labeled: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          jars: hdfs://analytics-hadoop/wmf/refinery/current/artifacts/refinery-hive.jar
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      feature_selection:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
          num-features: '50'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: feature_selection
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/pruned: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.maxExecutors: '400'
          spark.executor.memoryOverhead: '512'
          spark.locality.wait: '0'
          spark.task.cpus: '1'
      make_folds:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
          max-executors: '50'
          num-folds: '5'
          num-workers: '1'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: make_folds
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.maxExecutors: '100'
          spark.executor.memoryOverhead: '1536'
          spark.locality.wait: '0'
          spark.task.cpus: '1'
      pyspark:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/pyspark
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      pyspark_train:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '4'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/pyspark
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '6144'
          spark.task.cpus: '4'
      training_pipeline:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          cv-jobs: '125'
          final-trees: '100'
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
          output: /home/pytest/training_size/marker-medium
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: training_pipeline
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
            /home/pytest/training_size: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          driver-memory: 3G
          executor-cores: '4'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.executorIdleTimeout: 180s
          spark.dynamicAllocation.maxExecutors: '130'
          spark.executor.memoryOverhead: '2048'
          spark.task.cpus: '4'
    wikis:
    - itwiki
    - ptwiki
    - frwiki
    - ruwiki
  small:
    commands:
      collect_features:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          feature-definitions: featureset:enwiki_v1
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
          kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
          kafka-request-topic: mjolnir_request
          kafka-result-topic: mjolnir_result
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: collect_features
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/features: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      data_pipeline:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/wmf/data/discovery/query_clicks/daily/year=*/month=*/day=*
          kafka: kafka-jumbo1001.eqiad.wmnet:9092,kafka-jumbo1002.eqiad.wmnet:9092,kafka-jumbo1003.eqiad.wmnet:9092
          kafka-request-topic: mjolnir_request
          kafka-result-topic: mjolnir_result
          min-sessions: '10'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/labeled
          samples-per-wiki: '35000000'
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: data_pipeline
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/labeled: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          jars: hdfs://analytics-hadoop/wmf/refinery/current/artifacts/refinery-hive.jar
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      feature_selection:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/features
          num-features: '50'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: feature_selection
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          dir_not_exist: !!set
            /mnt/hdfs/user/pytest/mjolnir/marker/pruned: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.maxExecutors: '400'
          spark.executor.memoryOverhead: '512'
          spark.locality.wait: '0'
          spark.task.cpus: '1'
      make_folds:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/pruned
          max-executors: '50'
          num-folds: '5'
          num-workers: '1'
          output-dir: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: make_folds
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.maxExecutors: '100'
          spark.executor.memoryOverhead: '1024'
          spark.locality.wait: '0'
          spark.task.cpus: '1'
      pyspark:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '1'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/pyspark
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '512'
          spark.task.cpus: '1'
      pyspark_train:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          executor-cores: '4'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/pyspark
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.executor.memoryOverhead: '6144'
          spark.task.cpus: '4'
      training_pipeline:
        autodetect:
          agg_cpu_limit: '450'
          agg_memory_limit: 1T
          baseline_memory_overhead: 512M
          bytes_per_value:
            make_folds: '29'
            train: '20'
          executor_max_memory: 50G
        cmd_args:
          cv-jobs: '125'
          final-trees: '500'
          input: hdfs://analytics-hadoop/user/pytest/mjolnir/marker/folded
          output: /home/pytest/training_size/marker-small
        environment:
          HOME: /home/pytest
          PYSPARK_PYTHON: venv/bin/python
          SPARK_CONF_DIR: /etc/spark2/conf
          SPARK_HOME: /usr/lib/spark2
          USER: pytest
        mjolnir_utility: training_pipeline
        mjolnir_utility_path: /srv/mjolnir/venv/bin/mjolnir-utilities.py
        paths:
          dir_exist: !!set
            /etc/spark2/conf: null
            /home/pytest/training_size: null
          file_exist: !!set
            /srv/mjolnir/mjolnir_venv.zip: null
            /srv/mjolnir/venv/bin/mjolnir-utilities.py: null
            /usr/lib/spark2/bin/spark-submit: null
            venv/bin/python: null
        spark_args:
          archives: /srv/mjolnir/mjolnir_venv.zip#venv
          driver-memory: 3G
          executor-cores: '4'
          executor-memory: 2G
          files: /usr/lib/libhdfs.so.0.0.0
          master: yarn
          packages: ml.dmlc:xgboost4j-spark:0.8-wmf-2-SNAPSHOT,org.wikimedia.search:mjolnir:0.4-SNAPSHOT,sramirez:spark-infotheoretic-feature-selection:1.4.4,sramirez:spark-MDLP-discretization:1.4.1
          repositories: https://archiva.wikimedia.org/repository/releases,https://archiva.wikimedia.org/repository/snapshots,https://archiva.wikimedia.org/repository/mirrored
        spark_command: /usr/lib/spark2/bin/spark-submit
        spark_conf:
          spark.driver.extraJavaOptions: -Dhttp.proxyHost=webproxy.eqiad.wmnet -Dhttp.proxyPort=8080
            -Dhttps.proxyHost=webproxy.eqiad.wmnet -Dhttps.proxyPort=8080
          spark.dynamicAllocation.executorIdleTimeout: 180s
          spark.dynamicAllocation.maxExecutors: '130'
          spark.executor.memoryOverhead: '1024'
          spark.task.cpus: '4'
    wikis:
    - svwiki
    - fawiki
    - idwiki
    - viwiki
    - nowiki
    - hewiki
    - kowiki
    - fiwiki
    - jawiki
    - arwiki
    - nlwiki
    - zhwiki
    - plwiki
